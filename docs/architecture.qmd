---
title: "Architecture Overview"
---

`naq` is designed to be a simple yet powerful distributed task queue with a comprehensive event-driven architecture. Its architecture is fundamentally built around [NATS](https://nats.io) and its persistence layer, [JetStream](https://docs.nats.io/jetstream/jetstream), which serve as the central nervous system for communication between clients, workers, and the scheduler.

## Core Components

The `naq` ecosystem consists of four main components:

1.  **The Client (Producer)**: Any application that enqueues jobs. This could be a web server, a script, or any other part of your system that needs to offload work.
2.  **NATS Server (with JetStream)**: The message broker that provides persistence, message delivery, and storage for job results and worker metadata.
3.  **The Worker(s)**: The processes that subscribe to queues, execute jobs, and report back their results. You can run as many workers as you need, on as many machines as you want.
4.  **The Scheduler**: A dedicated process that handles time-based events, such as scheduled jobs and recurring tasks.

## How It Works: The Job Lifecycle

Here is a high-level overview of what happens when a job is enqueued and processed, including the comprehensive event-driven architecture:


```{mermaid}
graph TD
    subgraph "Your Application"
        Client[Client]
        PythonCode[Python Code]
        EventHandler[Event Handler]
    end

    subgraph "NAQ Processes"
        Worker[Worker]
        Scheduler[Scheduler]
        EventProcessor[Event Processor]
    end

    subgraph "NATS Server (JetStream)"
        QueueStream[Queue Stream]
        ResultStore[Result KV Store]
        ScheduledJobs[Scheduled Jobs KV]
        EventStream[Event Stream]
    end

    Client -- "1. Enqueue Job" --> QueueStream
    Scheduler -- "8. Check for Due Jobs" --> ScheduledJobs
    ScheduledJobs -- "Job is Due" --> Scheduler
    Scheduler -- "9. Enqueue Due Job" --> QueueStream
    Worker -- "3. Fetch Job" --> QueueStream
    Worker -- "4. Execute Function" --> PythonCode
    PythonCode -- "5. Return Result" --> Worker
    Worker -- "6. Store Result" --> ResultStore
    
    Client -- "2. Log ENQUEUED Event" --> EventStream
    Worker -- "Log STARTED/COMPLETED/FAILED Events" --> EventStream
    Scheduler -- "Log SCHEDULED Event" --> EventStream
    Worker -- "Log RETRY_SCHEDULED Event" --> EventStream
    Scheduler -- "Log SCHEDULE_TRIGGERED Event" --> EventStream
    Worker -- "Log CANCELLED Event" --> EventStream
    All Components -- "Log STATUS_CHANGED Events" --> EventStream
    
    EventStream -- "Stream Events" --> EventProcessor
    EventProcessor -- "Dispatch to Handlers" --> EventHandler
```

## The Central Event Stream Approach

At the heart of naq's architecture is a centralized event stream that captures all job lifecycle events. This event-driven approach enables:

- **Complete visibility**: Every job state change is captured and stored durably
- **Real-time monitoring**: Events are available immediately as they occur
- **Decoupled processing**: Components can react to events without direct coupling
- **Shared event logging**: All components use the same event logging infrastructure

### Shared Event Logging

All naq components (Client, Worker, Scheduler) use the shared event logging system provided by the `SharedEventLoggerManager`. This ensures:

- **Consistency**: All events follow the same format and structure
- **Reliability**: Events are buffered and flushed efficiently to prevent loss
- **Performance**: Non-blocking logging with configurable batching
- **Centralized configuration**: Event logging is managed through a single point

### The Complete Event Lifecycle

1.  **Enqueueing**: The client calls an `enqueue` function (e.g., `enqueue_sync`). The function, its arguments, and other metadata are serialized into a job payload. This payload is then published as a message to a NATS subject that corresponds to the target queue.

2.  **Event Logging (Enqueue)**: Upon successful enqueuing, the client (or `Queue` instance) logs an `ENQUEUED` event to the dedicated **Event Stream** using the shared event logger.

3.  **Persistence**: NATS JetStream receives this message and persists it in a **Stream**. Each queue in `naq` maps directly to a JetStream Stream. This ensures that even if no workers are online, the job is safely stored and will be processed later.

4.  **Fetching**: A `naq` worker process is constantly listening on the queue's Stream. When a new job is available, the worker consumes the message, acknowledging it to NATS so that it isn't delivered to another worker.

5.  **Status Change**: As the worker begins processing, it logs a `STATUS_CHANGED` event to indicate the job has moved from PENDING to RUNNING state.

6.  **Event Logging (Worker - Start)**: The worker logs a `STARTED` event when it begins processing a job.

7.  **Execution**: The worker deserializes the job payload and executes the specified Python function with the provided arguments.

8.  **Result Handling**: Once the function completes, its return value is serialized. The worker then stores this result in a NATS **Key-Value (KV) Store**, using the unique job ID as the key. This result has a configurable Time-To-Live (TTL), after which it is automatically purged by NATS.

9.  **Status Change**: Upon completion, the worker logs another `STATUS_CHANGED` event to indicate the final state (COMPLETED or FAILED).

10. **Event Logging (Worker - Completion)**: The worker logs `COMPLETED` events when jobs finish successfully, or `FAILED` events when jobs encounter errors. If a job fails and is configured for retry, a `RETRY_SCHEDULED` event is logged. If a job is cancelled, a `CANCELLED` event is logged.

11. **Scheduled Jobs**: The `naq scheduler` process periodically scans a dedicated KV store for jobs that are due to run. When it finds one, it enqueues it into the appropriate queue, and the job follows the normal lifecycle from there.

12. **Event Logging (Scheduler)**: The scheduler logs `SCHEDULED` events when a new scheduled job is created and `SCHEDULE_TRIGGERED` events when a scheduled job is enqueued for execution.

13. **Event Processing**: The `AsyncJobEventProcessor` subscribes to the **Event Stream**. It reads events in real-time and dispatches them to any registered event handlers, allowing for reactive, event-driven applications.

### New Event Types

The event-driven architecture includes several new event types that provide comprehensive visibility into job processing:

- **CANCELLED**: Logged when a job is cancelled before or during execution
- **STATUS_CHANGED**: Logged whenever a job's status changes, providing detailed state transition tracking

These new events, combined with the existing event types (ENQUEUED, STARTED, COMPLETED, FAILED, RETRY_SCHEDULED, SCHEDULED, SCHEDULE_TRIGGERED), provide a complete picture of the job lifecycle from creation to completion.

### Event Correlation

All events include the job ID, enabling easy correlation of events across the entire lifecycle. This allows you to:

- Track the complete journey of a single job
- Measure timing between different stages
- Identify bottlenecks in processing
- Build comprehensive monitoring and alerting systems

## Why NATS?

Using NATS and JetStream as the foundation provides several key advantages:

-   **Decoupling**: Clients, workers, and the scheduler are completely decoupled. They only need to know how to talk to NATS, not to each other directly.
-   **Scalability**: You can add more workers at any time to increase your processing capacity. NATS handles the load balancing of jobs to available workers automatically.
-   **Resilience**: If a worker crashes, JetStream ensures that the job it was processing will be re-delivered to another worker after a timeout. If the entire `naq` system goes down, the jobs are safe in the NATS stream, ready to be processed when the system comes back online.
-   **Simplicity**: By offloading the complexities of persistence, delivery guarantees, and storage to NATS, the `naq` codebase can remain focused on the core logic of job execution and scheduling.

## Service Layer Architecture

The service layer architecture is a recent addition to `naq` that addresses the challenge of connection management and resource utilization across the system. Previously, the codebase suffered from over 44+ duplicated NATS connection patterns, leading to inefficient resource usage and complex connection management.

### The Problem: Connection Pattern Duplication

Before the service layer, each component in `naq` (Queue, Worker, Scheduler, etc.) was responsible for creating and managing its own NATS connections. This approach led to several issues:

- **Resource Inefficiency**: Multiple connections to the same NATS server from the same process
- **Code Duplication**: Similar connection logic repeated across 44+ locations in the codebase
- **Inconsistent Configuration**: Connection parameters and retry logic varied between components
- **Difficult Maintenance**: Changes to connection handling required updates in multiple files
- **Connection Leaks**: No centralized management for connection lifecycle

### The Solution: Centralized Service Layer

The service layer architecture introduces a centralized approach to managing resources and dependencies through a set of specialized services:

#### Core Services

1. **ConnectionService**: Manages NATS connections and JetStream contexts
   - Provides connection pooling and reuse
   - Handles connection retries with exponential backoff
   - Centralizes connection configuration
   - Manages connection lifecycle and health checks

2. **StreamService**: Handles NATS JetStream stream operations
   - Stream creation, configuration, and management
   - Stream purging and message deletion
   - Stream information retrieval

3. **KVStoreService**: Manages NATS Key-Value store operations
   - Centralized KV store access patterns
   - TTL management for stored values
   - Transaction support for atomic operations

4. **JobService**: Handles job execution and result management
   - Job execution with proper error handling
   - Result storage and retrieval
   - Job failure handling and retry logic

5. **EventService**: Manages event logging and processing
   - Event batching and buffering
   - Event stream management
   - Event correlation and tracking

6. **SchedulerService**: Handles scheduled job management
   - Job scheduling and triggering
   - Recurring job management
   - Schedule persistence and retrieval

#### Service Manager

The [`ServiceManager`](src/naq/services/base.py:61) is the central component that:
- Creates and manages service instances
- Handles service dependencies
- Ensures proper initialization and cleanup
- Provides a unified interface for accessing services

### Benefits of the Service Layer

#### 1. Connection Pooling and Reuse

The service layer eliminates connection duplication by maintaining a pool of connections that can be shared across components:

```python
# Before: Each component creates its own connection
class Queue:
    async def _get_js(self):
        self._nc = await nats.connect(self._nats_url)
        self._js = self._nc.jetstream()
        return self._js

# After: Use centralized ConnectionService
class Queue:
    async def _get_js(self):
        if self._services is None:
            self._services = ServiceManager(self._config)
        
        connection_service = await self._services.get_service(ConnectionService)
        self._js = await connection_service.get_jetstream(self._nats_url)
        return self._js
```

#### 2. Centralized Error Handling

All services implement consistent error handling patterns with proper logging and retry logic:

```python
async def get_connection(self, url: Optional[str] = None) -> NATSClient:
    target_url = url if url is not None else self._default_url
    
    # Check if we already have a connection
    async with self._lock:
        if target_url in self._connections and self._connections[target_url].is_connected:
            return self._connections[target_url]
    
    # Create a new connection with retry logic
    return await self._create_connection_with_retry(target_url)
```

#### 3. Dependency Injection

Services can depend on other services, creating a clean dependency graph:

```python
# StreamService depends on ConnectionService
async def get_service(self, service_type: type) -> BaseService:
    if service_type == StreamService:
        # Get ConnectionService dependency
        connection_service = await self.get_service(ConnectionService)
        service = service_type(self.config, connection_service)
    # ... other service types
```

#### 4. Resource Lifecycle Management

The service layer ensures proper initialization and cleanup of all resources:

```python
async def __aenter__(self):
    await self.initialize()
    return self
    
async def __aexit__(self, exc_type, exc_val, exc_tb):
    await self.cleanup()
```

### Migration from Old Patterns

#### Before: Direct Connection Management

```python
# Old pattern - direct connection management
class OldQueue:
    def __init__(self, name, nats_url):
        self.name = name
        self.nats_url = nats_url
        self._nc = None
        self._js = None
    
    async def _get_js(self):
        if self._js is None:
            self._nc = await nats.connect(self.nats_url)
            self._js = self._nc.jetstream()
        return self._js
    
    async def close(self):
        if self._nc:
            await self._nc.close()
```

#### After: Service-Based Architecture

```python
# New pattern - service-based architecture
class NewQueue:
    def __init__(self, name, nats_url, services=None):
        self.name = name
        self.nats_url = nats_url
        self._services = services or ServiceManager({'nats': {'url': nats_url}})
        self._js = None
    
    async def _get_js(self):
        if self._js is None:
            connection_service = await self._services.get_service(ConnectionService)
            self._js = await connection_service.get_jetstream(self.nats_url)
        return self._js
    
    async def close(self):
        await self._services.cleanup_all()
```

### Service Layer in Action

Here's how the service layer works across different components:

```python
# Queue using services
async def enqueue_example():
    config = {'nats': {'url': 'nats://localhost:4222'}}
    
    async with ServiceManager(config) as services:
        queue = Queue(name='example', services=services)
        job = await queue.enqueue(my_function, arg1, arg2)
        
        # All connections managed by the service layer
        # No need to manually close connections

# Worker using services
async def worker_example():
    config = {'nats': {'url': 'nats://localhost:4222'}}
    
    async with ServiceManager(config) as services:
        worker = Worker(queues=['example'], services=services)
        await worker.run()
        
        # Services automatically cleaned up when context exits
```

### Best Practices for Using the Service Layer

1. **Use ServiceManager for Lifecycle Management**: Always use the ServiceManager as a context manager to ensure proper cleanup.

2. **Share ServiceManager Instances**: When possible, share a single ServiceManager instance across components in the same process.

3. **Configure Services Properly**: Provide appropriate configuration for connection parameters, retry logic, and timeouts.

4. **Handle Service Errors**: Implement proper error handling for service-related exceptions.

5. **Use Dependency Injection**: Leverage the service dependency system rather than manually creating service instances.

The service layer architecture represents a significant improvement in the design of `naq`, eliminating code duplication, improving resource efficiency, and providing a solid foundation for future enhancements.

## Connection Management

The connection management system has been completely refactored to provide:

1. **Context Manager API**: Modern, resource-safe connection management
2. **Service Integration**: Seamless integration with the service layer
3. **Monitoring Capabilities**: Built-in connection metrics and health monitoring
4. **Configuration-Driven**: All connection parameters driven by configuration

### Architecture Flow

```
Application Code
    ↓ (Context Managers or Decorators)
Connection Module (context_managers.py, utils.py, decorators.py)
    ↓ (Optional Service Integration)
ConnectionService (services/connection.py)
    ↓
NATS Client
```

### Key Benefits

- **Automatic Resource Management**: Context managers ensure proper cleanup
- **Reduced Boilerplate**: Eliminates manual connection handling code
- **Consistent Patterns**: Uniform connection handling across all modules
- **Production Ready**: Built-in monitoring and health checking

### Context Manager Implementation

The new connection management system provides several context managers for different use cases:

```python
# Basic NATS connection
async with nats_connection() as conn:
    await conn.publish("subject", b"message")

# JetStream context
async with nats_jetstream() as (conn, js):
    await js.add_stream(name="stream", subjects=["stream.*"])

# KeyValue operations
async with nats_kv_store("bucket") as kv:
    await kv.put("key", "value")
```

### Connection Monitoring

The system includes comprehensive monitoring capabilities:

```python
from naq.connection import connection_monitor

# Track connection metrics
print(f"Total connections: {connection_monitor.metrics.total_connections}")
print(f"Active connections: {connection_monitor.metrics.active_connections}")
print(f"Failed connections: {connection_monitor.metrics.failed_connections}")
```

### Integration with Service Layer

The connection management system integrates seamlessly with the service layer:

```python
# Using context managers with services
async with ServiceManager(config) as services:
    connection_service = await services.get_service(ConnectionService)
    
    # Context managers can use the same underlying connections
    async with nats_connection() as conn:
        # Connection is managed by both the context manager and service layer
        await conn.publish("subject", b"message")
```

### Migration Path

The connection management system provides a clear migration path from legacy patterns:

#### Legacy Pattern
```python
# Old approach - manual connection management
nc = await get_nats_connection(url)
try:
    js = await get_jetstream_context(nc)
    await js.add_stream(config)
finally:
    await close_nats_connection(nc)
```

#### Modern Pattern
```python
# New approach - automatic resource management
async with nats_jetstream(config) as (conn, js):
    await js.add_stream(config)
```

### Backward Compatibility

The new connection management system maintains full backward compatibility with existing code. All legacy functions continue to work unchanged, while new code can benefit from the improved context manager API.

### Production Considerations

For production deployments, the connection management system provides:

1. **Connection Pooling**: Efficient reuse of connections across components
2. **Health Monitoring**: Built-in connection health checks and metrics
3. **Error Handling**: Comprehensive error handling and retry logic
4. **Configuration Management**: Centralized configuration for all connection parameters

This refactored connection management system significantly improves the reliability and maintainability of `naq` while providing a modern, Pythonic API for developers.

## Utils Package Architecture

The `utils` package is a comprehensive collection of utilities extracted from various modules throughout the codebase as part of Task 08. It provides common functionality used across all components of `naq`, eliminating code duplication and providing a consistent set of tools for common operations.

### Package Structure

The `utils` package is organized into specialized modules, each focusing on a specific area of functionality:

```
src/naq/utils/
├── __init__.py
├── async_helpers.py      # Async/sync conversion utilities
├── config.py            # Configuration management
├── context_managers.py  # Common context managers
├── decorators.py        # Reusable decorators
├── error_handling.py    # Centralized error handling
├── logging.py           # Logging utilities
├── nats_helpers.py      # NATS-specific utilities
├── retry.py             # Retry mechanisms
├── serialization.py     # Serialization helpers
├── timing.py            # Timing and benchmarking
├── types.py             # Common type definitions
└── validation.py        # Validation utilities
```

### Core Utilities

#### 1. Async Helpers (`async_helpers.py`)

Provides utilities for bridging synchronous and asynchronous code:

- **`run_async()`**: Execute async functions from sync code
- **`run_sync()`**: Execute sync functions from async code
- **`async_to_sync()`**: Convert async functions to sync functions
- **`sync_to_async()`**: Convert sync functions to async functions
- **`asyncify()`**: Decorator to make sync functions async-compatible

#### 2. Configuration Management (`config.py`)

Centralized configuration system with multiple source support:

- **`ConfigManager`**: Manages configuration from multiple sources with priority-based merging
- **`ConfigSource`**: Base class for configuration sources
- **EnvironmentConfigSource`**: Reads from environment variables
- **`FileConfigSource`**: Reads from YAML/JSON files
- **`DictConfigSource`**: Uses provided dictionaries
- **Configuration dataclasses**: Predefined configuration structures for different components

#### 3. Context Managers (`context_managers.py`)

Common context managers for resource management:

- **`managed_resource()`**: Generic resource management with cleanup
- **`timeout_context()`**: Timeout management for operations
- **`retry_context()`**: Retry logic with context management
- **`benchmark_context()`**: Performance benchmarking

#### 4. Decorators (`decorators.py`)

Reusable decorators for common patterns:

- **`retry_decorator()`**: Automatic retry logic with configurable strategies
- **`timeout_decorator()`**: Timeout enforcement for functions
- **`benchmark_decorator()`**: Performance measurement
- **`log_errors()`**: Automatic error logging
- **`validate_args()`**: Argument validation

#### 5. Error Handling (`error_handling.py`)

Centralized error handling and reporting:

- **`ErrorContext`**: Rich error context with metadata
- **`ErrorCategory`**: Categorization of errors
- **`ErrorHandler`**: Centralized error handling strategies
- **`ErrorReporter`**: Structured error reporting
- **Recovery strategies**: Configurable recovery mechanisms

#### 6. Logging (`logging.py`)

Comprehensive logging utilities:

- **Structured logging**: Context-aware logging with rich metadata
- **Performance logging**: Specialized logging for performance metrics
- **Log handler management**: Centralized log handler configuration
- **Log correlation**: Request/operation ID tracking

#### 7. NATS Helpers (`nats_helpers.py`)

NATS-specific utilities extracted from connection modules:

- **Connection management**: Context managers for NATS connections
- **Stream operations**: Stream creation and management utilities
- **KV store operations**: Key-value store operations with retry logic
- **Subject utilities**: Subject building and parsing
- **Message handling**: Message publishing and subscription utilities
- **Connection monitoring**: Connection metrics and health monitoring

#### 8. Retry Mechanisms (`retry.py`)

Comprehensive retry system:

- **`RetryConfig`**: Configurable retry strategies
- **`retry_async()`**: Async retry with exponential backoff
- **`retry()`**: Sync retry with exponential backoff
- **Retry strategies**: Linear, exponential, custom strategies
- **Jitter support**: Avoid thundering herd problems

#### 9. Serialization (`serialization.py`)

Serialization utilities for jobs and results:

- **`JobSerializer`**: Job serialization with multiple formats
- **`ResultSerializer`**: Result serialization with TTL support
- **`SecureSerializer`**: Security-focused serialization
- **Serializer protocol**: Extensible serialization interface

#### 10. Timing and Benchmarking (`timing.py`)

Performance measurement and timing utilities:

- **`Timer`**: High-resolution timing for operations
- **`AsyncTimer`**: Async-compatible timing
- **`Benchmark`**: Comprehensive benchmarking tools
- **`Scheduler`**: Time-based scheduling utilities
- **Performance tracking**: Long-term performance monitoring

#### 11. Type Definitions (`types.py`)

Comprehensive type definitions for the entire system:

- **Basic type aliases**: Common types used throughout the codebase
- **Protocol definitions**: Interface definitions for common patterns
- **Generic types**: Reusable generic types
- **Type validation helpers**: Runtime type checking utilities
- **Model types**: Type definitions for core models
- **Configuration types**: Type definitions for configuration

#### 12. Validation (`validation.py`)

Comprehensive validation utilities:

- **Type validation**: Runtime type checking
- **Range validation**: Numeric range checking
- **Choice validation**: Enum/value choice validation
- **String validation**: String format validation
- **URL/email validation**: Specialized string validation
- **Dictionary validation**: Nested dictionary validation
- **Dataclass validation**: Automatic dataclass validation

### Integration with Core Components

The utils package integrates seamlessly with all core components of `naq`:

#### Queue Integration
```python
from naq.utils import retry_async, ErrorContext, ErrorCategory
from naq.utils.nats_helpers import nats_jetstream_context

class Queue:
    async def enqueue(self, func, *args, **kwargs):
        async with nats_jetstream_context() as (conn, js):
            return await retry_async(
                self._enqueue_impl,
                func, args, kwargs, js
            )
```

#### Worker Integration
```python
from naq.utils import Timer, ErrorContext
from naq.utils.logging import get_structured_logger

class Worker:
    async def process_job(self, job):
        with Timer() as timer:
            logger = get_structured_logger("worker")
            try:
                result = await job.execute()
                logger.info("Job completed", job_id=job.id, duration=timer.duration)
                return result
            except Exception as e:
                error_context = ErrorContext(
                    operation="job_execution",
                    exception=e,
                    job_id=job.id
                )
                error_context.category = ErrorCategory.EXECUTION
                logger.error("Job failed", error_context=error_context)
                raise
```

#### Service Layer Integration
```python
from naq.utils.config import ConfigManager, load_naq_config
from naq.utils.types import Result, Error

class ServiceManager:
    def __init__(self, config=None):
        self.config = config or load_naq_config()
        self._config_manager = ConfigManager([DictConfigSource(self.config)])
```

### Benefits of the Utils Package

#### 1. Code Consolidation
- Eliminates duplication of common patterns across 44+ locations
- Provides single source of truth for common functionality
- Reduces maintenance burden and bug potential

#### 2. Consistency
- Unified error handling across all components
- Consistent logging formats and correlation
- Standardized retry and timeout behavior

#### 3. Testability
- All utilities are thoroughly tested
- Mockable interfaces for easy unit testing
- Clear separation of concerns

#### 4. Extensibility
- Protocol-based design allows easy extension
- Plugin architecture for custom serializers, validators, etc.
- Configurable behavior through settings

#### 5. Performance
- Optimized implementations for critical paths
- Minimal overhead for common operations
- Efficient resource management

### Migration Path

The utils package provides a clear migration path from the old scattered utilities:

#### Before: Scattered Utilities
```python
# In queue.py
def _get_nats_connection(self):
    # Custom connection logic
    pass

# In worker.py
def _get_nats_connection(self):
    # Similar but slightly different connection logic
    pass

# In scheduler.py
def _get_nats_connection(self):
    # Another variation of connection logic
    pass
```

#### After: Centralized Utils
```python
# In all components
from naq.utils.nats_helpers import nats_connection_context

async def _get_nats_connection(self):
    async with nats_connection_context() as conn:
        return conn
```

### Best Practices

#### 1. Using Utils in Components
```python
# Import specific utilities
from naq.utils import retry_async, Timer, ErrorContext
from naq.utils.nats_helpers import nats_jetstream_context
from naq.utils.logging import get_structured_logger

# Use in component methods
async def process_request(self, request):
    with Timer() as timer:
        logger = get_structured_logger("component")
        
        try:
            async with nats_jetstream_context() as (conn, js):
                result = await retry_async(
                    self._process_impl,
                    request, js
                )
                
                logger.info(
                    "Request processed",
                    request_id=request.id,
                    duration=timer.duration
                )
                return result
                
        except Exception as e:
            error_context = ErrorContext(
                operation="request_processing",
                exception=e,
                request_id=request.id
            )
            logger.error("Request failed", error_context=error_context)
            raise
```

#### 2. Configuration Management
```python
from naq.utils.config import ConfigManager, EnvironmentConfigSource, FileConfigSource

# Create configuration manager with multiple sources
config_manager = ConfigManager([
    EnvironmentConfigSource(prefix="MYAPP_"),
    FileConfigSource("config.yaml"),
    DictConfigSource({"default": "values"})
])

# Use typed configuration
max_retries = config_manager.get_typed("max_retries", int, 3)
timeout = config_manager.get_required_typed("timeout", float)
```

#### 3. Error Handling
```python
from naq.utils import ErrorContext, ErrorCategory, ErrorReporter

async def risky_operation(self):
    try:
        return await self._do_risky_thing()
    except Exception as e:
        error_context = ErrorContext(
            operation="risky_operation",
            exception=e,
            component=self.__class__.__name__
        )
        error_context.category = ErrorCategory.EXECUTION
        error_context.add_metadata({"attempt": self._attempt})
        
        reporter = ErrorReporter()
        await reporter.report_error(error_context)
        raise
```

#### 4. Performance Monitoring
```python
from naq.utils import Timer, Benchmark
from naq.utils.timing import Scheduler

# Time individual operations
async def process_item(self, item):
    with Timer() as timer:
        result = await self._process_item_impl(item)
        
        # Log timing metrics
        self.metrics.observe("process_item_duration", timer.duration)
        return result

# Benchmark operations
async def benchmark_processing(self):
    benchmark = Benchmark()
    
    async with benchmark:
        for i in range(1000):
            await self.process_item(f"item_{i}")
    
    print(f"Processed 1000 items in {benchmark.total_time:.2f}s")
    print(f"Average time: {benchmark.average_time:.4f}s")
    print(f"Min time: {benchmark.min_time:.4f}s")
    print(f"Max time: {benchmark.max_time:.4f}s")
```

The utils package represents a significant architectural improvement for `naq`, providing a solid foundation of reusable, well-tested utilities that eliminate code duplication and ensure consistency across all components of the system.