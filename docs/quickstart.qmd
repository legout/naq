---
title: "Quickstart Guide"
---

This guide will walk you through the basics of setting up a task, enqueuing it, and running a worker to process it.

## 1. Define a Task

First, create a Python file to define the function you want to run in the background. Let's call this file `tasks.py`.

This function can be any regular Python function. For this example, we'll create a simple function that simulates some work and counts the words in a given text.

```python
# tasks.py
import time
import random

def count_words(text):
    """
    A simple function that counts the words in a string.
    """
    print(f"Processing text: '{text[:30]}...'")
    # Simulate some I/O or CPU-bound work
    time.sleep(random.randint(1, 3))
    word_count = len(text.split())
    print(f"Found {word_count} words.")
    return word_count
```

## 2. Enqueue the Job

Now, let's enqueue the `count_words` function to be executed by a worker. Create another file, `main.py`, to send the job to the queue.

### Using Queue with ServiceManager (Recommended)

The recommended approach is to use a `Queue` instance initialized with a `ServiceManager`. This provides efficient connection management and leverages the service layer internally.

```python
# main.py
from naq.queue import Queue
from naq.services import ServiceManager
from tasks import count_words

# The text we want to process
long_text = (
    "A journey of a thousand miles begins with a single step. "
    "The best time to plant a tree was 20 years ago. "
    "The second best time is now."
)

print("Enqueuing job to count words...")

# Create a Queue instance with ServiceManager
async def enqueue_job():
    async with ServiceManager() as services:
        queue = Queue(name="default", services=services)
        job = await queue.enqueue(count_words, long_text)
        print(f"Successfully enqueued job {job.job_id}.")
        return job

# Run the async function
import asyncio
job = asyncio.run(enqueue_job())

print("To process the job, run a worker with: naq worker default")
```

### Using enqueue_sync (Simplified)

For simpler use cases, you can still use the `enqueue_sync` function. Note that it now internally leverages the service layer for connection management and job processing.

```python
# main_simple.py
from naq import enqueue_sync
from tasks import count_words

# The text we want to process
long_text = (
    "A journey of a thousand miles begins with a single step. "
    "The best time to plant a tree was 20 years ago. "
    "The second best time is now."
)

print("Enqueuing job to count words...")

# Enqueue the function `count_words` with `long_text` as its argument
job = enqueue_sync(count_words, long_text)

print(f"Successfully enqueued job {job.job_id}.")
print("To process the job, run a worker with: naq worker default")
```

## 3. Run the Worker

With the job enqueued, the final step is to start a worker process. The worker will connect to NATS, fetch the job from the queue, and execute the `count_words` function.

Open your terminal and run the following command:

```bash
naq worker default
```

The `default` argument tells the worker to listen to the default queue, which is where `enqueue_sync` sends jobs.

You should see output similar to this in your worker's terminal:

```
14:30:15.123 INFO     Worker listening on queue: naq_default_queue
Processing text: 'A journey of a thousand miles...'
Found 25 words.
14:30:18.245 INFO     Job 1a2b3c4d completed. Result: 25
```

Congratulations! You've successfully enqueued and processed your first background job with `naq`.

## Connection Management

### Service-Based Connection Management (Recommended)

The recommended way to manage NATS connections in `naq` is through the `ServiceManager`. It provides centralized connection management, automatic resource pooling, and simplifies application-level connection handling.

```python
import asyncio
from naq.queue import Queue
from naq.services import ServiceManager

async def service_manager_example():
    # Create ServiceManager with configuration
    async with ServiceManager() as services:
        # Get a Queue instance that uses the service layer
        queue = Queue(name="my_queue", services=services)
        
        # The Queue internally uses services for connection management
        job = await queue.enqueue(my_task, arg1, arg2)
        print(f"Job enqueued: {job.job_id}")
        
        # Services handle connection pooling, reuse, and cleanup automatically
        # No manual connection management needed at the application level
```

### Using Context Managers (Lower-Level Usage)

Direct usage of context managers is still available but is primarily intended for lower-level operations or service-internal use cases. These provide fine-grained control over NATS connections when needed.

```python
import asyncio
from naq.utils.nats_helpers import nats_connection_context, nats_jetstream_context, nats_kv_store_context

async def low_level_example():
    # Simple connection
    async with nats_connection_context() as conn:
        await conn.publish("hello", b"world")
    
    # With JetStream
    async with nats_jetstream_context() as (conn, js):
        stream = await js.add_stream(name="mystream", subjects=["mystream.*"])
    
    # With KeyValue store
    async with nats_kv_store_context("mybucket") as kv:
        await kv.put("key", "value")
```

### Using Decorators

For functions that need NATS connections, you can use decorators to automatically inject connections:

```python
from naq.utils.decorators import with_nats_connection, with_jetstream_context

@with_nats_connection()
async def publish(conn, subject: str, data: bytes):
    await conn.publish(subject, data)

@with_jetstream_context()
async def create_stream(js, name: str):
    await js.add_stream(name=name, subjects=[f"{name}.*"])
```

### Connection Testing and Monitoring

In production environments, you can test and monitor your connections:

```python
from naq.utils.nats_helpers import test_nats_connection, wait_for_nats_connection, get_connection_metrics

# Test if connection is available
is_healthy = await test_nats_connection()

# Wait for connection to be ready
await wait_for_nats_connection(timeout=30)

# Monitor connection usage
metrics = get_connection_metrics()
print(f"Active connections: {metrics.active_connections}")
```

## What's Next?

-   Explore how to [schedule jobs](examples.qmd) to run in the future.
-   Learn about the [architecture](architecture.qmd) of `naq`.
-   Check out more complex [examples](examples.qmd).
-   Read the [Connection Management API](api/connection.qmd) documentation for advanced usage.