[
  {
    "objectID": "api/exceptions.html",
    "href": "api/exceptions.html",
    "title": "Exceptions",
    "section": "",
    "text": "The naq library uses a set of custom exceptions to indicate specific error conditions. All custom exceptions inherit from the base NaqException.\n\nNaqException\nThe base exception for all errors raised by naq.\n\n\nNaqConnectionError\nRaised when there is an issue connecting to the NATS server or a problem with the connection during an operation.\n\n\nConfigurationError\nRaised when there is an issue with the configuration of naq, such as providing invalid parameters to a Queue or Worker.\n\n\nSerializationError\nRaised if naq fails to serialize or deserialize a job. This can happen if you are using the json serializer and try to enqueue a job with un-serializable arguments (like complex objects).\n\n\nJobExecutionError\nRaised by Job.fetch_result() if the job failed during execution on the worker. The exception message will contain the original error and traceback from the worker.\n\n\nJobNotFoundError\nRaised by Job.fetch_result() if the result for the specified job_id cannot be found. This could be because the job has not completed yet, the result has expired and been cleaned up, or the job never existed."
  },
  {
    "objectID": "api/worker.html",
    "href": "api/worker.html",
    "title": "Worker API",
    "section": "",
    "text": "The worker module contains the Worker class, which is responsible for fetching and executing jobs from one or more queues."
  },
  {
    "objectID": "api/worker.html#naq.worker.worker",
    "href": "api/worker.html#naq.worker.worker",
    "title": "Worker API",
    "section": "naq.worker.Worker",
    "text": "naq.worker.Worker\nYou can start a worker from the command line using naq worker, but you can also create and run a Worker instance programmatically.\n\nnaq.worker.Worker(queues, nats_url, concurrency, worker_name, ...)\n\n\n\n\n\n\n\n\nParameter\nType\nDescription\n\n\n\n\nqueues\nlist[str] | str\nA list of queue names to listen to. Defaults to the single naq_default_queue.\n\n\nnats_url\nstr\nThe URL of the NATS server.\n\n\nconcurrency\nint\nThe maximum number of jobs to process concurrently. Defaults to 10.\n\n\nworker_name\nstr | None\nA name for the worker, used for creating durable consumer names. A unique ID is generated if not provided.\n\n\nheartbeat_interval\nint\nThe interval (in seconds) at which the worker sends a heartbeat. Defaults to 15.\n\n\nworker_ttl\nint\nThe time-to-live (in seconds) for the worker’s heartbeat. Defaults to 60.\n\n\nack_wait\nint | dict | None\nThe time (in seconds) the worker has to acknowledge a job before it’s re-delivered. Can be a global value or a per-queue dictionary.\n\n\nmodule_paths\nlist[str] | str | None\nA list of paths to add to sys.path to help the worker find your task modules.\n\n\n\n\n\nMethods\n\nrun()\nStarts the worker’s main processing loop. This is an async method.\nasync def run(self) -&gt; None\nThe worker will connect to NATS, subscribe to the specified queues, and start fetching jobs. It will run until a shutdown signal is received.\n\n\nrun_sync()\nA synchronous method to start the worker. This is useful when running a worker from a synchronous script.\ndef run_sync(self) -&gt; None\nThis method will block until the worker is shut down.\n\n\nlist_workers()\nA static method to list all active workers.\n@staticmethod\nasync def list_workers(nats_url: str = DEFAULT_NATS_URL) -&gt; list[dict]\nReturns a list of dictionaries, where each dictionary contains information about a worker (ID, status, hostname, etc.).\n\n\nlist_workers_sync()\nA synchronous version of list_workers()."
  },
  {
    "objectID": "api/queue.html",
    "href": "api/queue.html",
    "title": "Queue API",
    "section": "",
    "text": "The queue module provides the primary interface for adding jobs to naq."
  },
  {
    "objectID": "api/queue.html#queue-class",
    "href": "api/queue.html#queue-class",
    "title": "Queue API",
    "section": "Queue Class",
    "text": "Queue Class\nThe Queue class represents a job queue and is the main entry point for enqueuing tasks.\n\n\n\n\n\n\nNote\n\n\n\nFor simple, one-off enqueueing, you might prefer the helper functions like enqueue which manage the Queue instance for you.\n\n\n\nnaq.queue.Queue(name, nats_url, default_timeout)\n\n\n\n\n\n\n\n\nParameter\nType\nDescription\n\n\n\n\nname\nstr\nThe name of the queue. Defaults to naq_default_queue.\n\n\nnats_url\nstr\nThe URL of the NATS server. Defaults to nats://localhost:4222.\n\n\ndefault_timeout\nint | None\nThe default timeout in seconds for jobs in this queue.\n\n\n\n\n\nMethods\n\nenqueue()\nEnqueues a job for immediate execution.\nasync def enqueue(\n    self,\n    func: Callable,\n    *args: Any,\n    max_retries: Optional[int] = 0,\n    retry_delay: RetryDelayType = 0,\n    depends_on: Optional[Union[str, List[str], Job, List[Job]]] = None,\n    timeout: Optional[int] = None,\n    **kwargs: Any\n) -&gt; Job\n\n\nenqueue_at()\nSchedules a job to be enqueued at a specific datetime.\nasync def enqueue_at(\n    self,\n    dt: datetime.datetime,\n    func: Callable,\n    *args: Any,\n    ...\n) -&gt; Job\n\n\nenqueue_in()\nSchedules a job to be enqueued after a timedelta.\nasync def enqueue_in(\n    self,\n    delta: timedelta,\n    func: Callable,\n    *args: Any,\n    ...\n) -&gt; Job\n\n\nschedule()\nSchedules a job to run on a recurring basis.\nasync def schedule(\n    self,\n    func: Callable,\n    *args: Any,\n    cron: Optional[str] = None,\n    interval: Optional[Union[timedelta, float, int]] = None,\n    repeat: Optional[int] = None,\n    ...\n) -&gt; Job\n\n\n\n\n\n\n\n\nParameter\nType\nDescription\n\n\n\n\ncron\nstr\nA cron string (e.g., '*/5 * * * *') for the schedule.\n\n\ninterval\ntimedelta | float | int\nThe interval in seconds or as a timedelta between job runs.\n\n\nrepeat\nint | None\nThe number of times to repeat the job. None for indefinitely.\n\n\n\n\n\npurge()\nRemoves all jobs from the queue.\nasync def purge(self) -&gt; int\nReturns the number of jobs purged.\n\n\ncancel_scheduled_job()\nCancels a scheduled or recurring job.\nasync def cancel_scheduled_job(self, job_id: str) -&gt; bool\nReturns True if the job was found and canceled."
  },
  {
    "objectID": "api/queue.html#enqueue-functions",
    "href": "api/queue.html#enqueue-functions",
    "title": "Queue API",
    "section": "Enqueue Functions",
    "text": "Enqueue Functions\nThese helper functions provide a simpler way to enqueue jobs without needing to manage a Queue instance yourself. They are available in both async and sync versions.\n\nAsync Helpers\n\nnaq.enqueue()\nnaq.enqueue_at()\nnaq.enqueue_in()\nnaq.schedule()\nnaq.purge_queue()\nnaq.cancel_scheduled_job()\n\n\n\nSync Helpers\nFor use in synchronous code, naq provides sync versions of the enqueue functions. These functions automatically manage an event loop and use a thread-local connection for efficiency.\n\nnaq.enqueue_sync()\nnaq.enqueue_at_sync()\nnaq.enqueue_in_sync()\nnaq.schedule_sync()\nnaq.purge_queue_sync()\nnaq.cancel_scheduled_job_sync()\nnaq.close_sync_connections()"
  },
  {
    "objectID": "advanced.html",
    "href": "advanced.html",
    "title": "Advanced Usage",
    "section": "",
    "text": "This section covers advanced features and configuration options for optimizing naq in production environments."
  },
  {
    "objectID": "advanced.html#efficient-connection-handling-batching",
    "href": "advanced.html#efficient-connection-handling-batching",
    "title": "Advanced Usage",
    "section": "Efficient Connection Handling & Batching",
    "text": "Efficient Connection Handling & Batching\nWhen enqueuing many jobs in a tight loop, creating a new NATS connection for each job is inefficient. naq provides several ways to manage connections for high-throughput scenarios.\n\nUsing a Queue Instance (Async)\nFor asynchronous applications, the most efficient way to enqueue jobs is to instantiate a Queue object and reuse it. The Queue instance manages a persistent connection to NATS.\n# async_batch_enqueue.py\nimport asyncio\nfrom naq.queue import Queue\n\nasync def my_task(i):\n    return f\"Processed item {i}\"\n\nasync def main():\n    # Create a single Queue instance for the 'high_volume' queue\n    queue = Queue(name=\"high_volume\")\n\n    print(\"Enqueuing 1,000 jobs using a single connection...\")\n    tasks = []\n    for i in range(1000):\n        task = queue.enqueue(my_task, i)\n        tasks.append(task)\n\n    await asyncio.gather(*tasks)\n    print(\"All jobs enqueued.\")\n\n    # The connection remains open until the Queue object is no longer in use\n    # or explicitly closed.\n    await queue.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n\nThread-Local Connections (Sync)\nThe synchronous helper functions (enqueue_sync, enqueue_at_sync, etc.) are optimized for batching out of the box. They automatically use a thread-local NATS connection. This means that all calls to these functions from the same thread will reuse the same connection, avoiding the overhead of reconnecting each time.\n# sync_batch_enqueue.py\nfrom naq import enqueue_sync, close_sync_connections\n\ndef my_task(i):\n    return f\"Processed item {i}\"\n\ndef main():\n    print(\"Enqueuing 1,000 jobs using a thread-local connection...\")\n    for i in range(1000):\n        enqueue_sync(my_task, i)\n    print(\"All jobs enqueued.\")\n\n    # Optionally, you can explicitly close the thread-local connection\n    # when you are done with a batch. This is not required, as connections\n    # are also closed on process exit.\n    close_sync_connections()\n    print(\"Thread-local connection closed.\")\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
    "objectID": "advanced.html#configuration-via-environment-variables",
    "href": "advanced.html#configuration-via-environment-variables",
    "title": "Advanced Usage",
    "section": "Configuration via Environment Variables",
    "text": "Configuration via Environment Variables\nMany of naq’s settings can be configured using environment variables, which is ideal for production and containerized deployments.\n\n\n\n\n\n\n\n\nVariable\nDefault\nDescription\n\n\n\n\nNAQ_NATS_URL\nnats://localhost:4222\nThe URL of the NATS server.\n\n\nNAQ_DEFAULT_QUEUE\nnaq_default_queue\nThe default queue name used when none is specified.\n\n\nNAQ_JOB_SERIALIZER\npickle\nThe serializer for jobs. Can be pickle or json. See security note below.\n\n\nNAQ_DEFAULT_RESULT_TTL\n604800 (7 days)\nDefault time-to-live (in seconds) for job results stored in NATS.\n\n\nNAQ_SCHEDULER_LOCK_TTL\n30\nTTL (in seconds) for the scheduler’s high-availability leader lock.\n\n\nNAQ_WORKER_TTL\n60\nTTL (in seconds) for a worker’s heartbeat. If a worker is silent for this long, it’s considered dead.\n\n\nNAQ_WORKER_HEARTBEAT_INTERVAL\n15\nHow often (in seconds) a worker sends a heartbeat to NATS.\n\n\nNAQ_LOG_LEVEL\nCRITICAL\nThe logging level for naq components. Can be DEBUG, INFO, WARNING, ERROR."
  },
  {
    "objectID": "advanced.html#job-serialization-pickle-vs.-json",
    "href": "advanced.html#job-serialization-pickle-vs.-json",
    "title": "Advanced Usage",
    "section": "Job Serialization (pickle vs. json)",
    "text": "Job Serialization (pickle vs. json)\nnaq uses a serializer to convert job data (the function and its arguments) into a format that can be stored in NATS. You can choose between two built-in serializers.\n\npickle (Default)\n\nPros: Can serialize almost any Python object, including complex custom classes, lambdas, and functions defined in a REPL.\nCons: Not secure. A malicious actor who can enqueue jobs could craft a pickle payload that executes arbitrary code on your workers.\n\n\n\njson (Recommended for Production)\n\nPros: Secure. Only serializes basic data types (strings, numbers, lists, dicts). Functions are referenced by their import path (e.g., my_app.tasks.process_data), not serialized directly. This prevents arbitrary code execution.\nCons: Less flexible. Cannot serialize complex Python objects that don’t have a natural JSON representation.\n\nTo use the json serializer, set the following environment variable:\nexport NAQ_JOB_SERIALIZER=json\n\n\n\n\n\n\nWarning\n\n\n\nSecurity Warning\nIt is strongly recommended to use the json serializer in any environment where the job producer is not fully trusted."
  },
  {
    "objectID": "architecture.html",
    "href": "architecture.html",
    "title": "Architecture Overview",
    "section": "",
    "text": "naq is designed to be a simple yet powerful distributed task queue. Its architecture is fundamentally built around NATS and its persistence layer, JetStream, which serve as the central nervous system for communication between clients, workers, and the scheduler."
  },
  {
    "objectID": "architecture.html#core-components",
    "href": "architecture.html#core-components",
    "title": "Architecture Overview",
    "section": "Core Components",
    "text": "Core Components\nThe naq ecosystem consists of four main components:\n\nThe Client (Producer): Any application that enqueues jobs. This could be a web server, a script, or any other part of your system that needs to offload work.\nNATS Server (with JetStream): The message broker that provides persistence, message delivery, and storage for job results and worker metadata.\nThe Worker(s): The processes that subscribe to queues, execute jobs, and report back their results. You can run as many workers as you need, on as many machines as you want.\nThe Scheduler: A dedicated process that handles time-based events, such as scheduled jobs and recurring tasks."
  },
  {
    "objectID": "architecture.html#how-it-works-the-job-lifecycle",
    "href": "architecture.html#how-it-works-the-job-lifecycle",
    "title": "Architecture Overview",
    "section": "How It Works: The Job Lifecycle",
    "text": "How It Works: The Job Lifecycle\nHere is a high-level overview of what happens when a job is enqueued and processed:\n\n\n\n\n\ngraph TD\n    subgraph \"Your Application\"\n        Client[Client]\n        PythonCode[Python Code]\n    end\n\n    subgraph \"NAQ Processes\"\n        Worker[Worker]\n        Scheduler[Scheduler]\n    end\n\n    subgraph \"NATS Server (JetStream)\"\n        QueueStream[Queue Stream]\n        ResultStore[Result KV Store]\n        ScheduledJobs[Scheduled Jobs KV]\n    end\n\n    Client -- \"1. Enqueue Job\" --&gt; QueueStream\n    Scheduler -- \"7. Check for Due Jobs\" --&gt; ScheduledJobs\n    ScheduledJobs -- \"Job is Due\" --&gt; Scheduler\n    Scheduler -- \"8. Enqueue Due Job\" --&gt; QueueStream\n    Worker -- \"3. Fetch Job\" --&gt; QueueStream\n    Worker -- \"4. Execute Function\" --&gt; PythonCode\n    PythonCode -- \"5. Return Result\" --&gt; Worker\n    Worker -- \"6. Store Result\" --&gt; ResultStore\n\n\n\n\n\n\n\nEnqueueing: The client calls an enqueue function (e.g., enqueue_sync). The function, its arguments, and other metadata are serialized into a job payload. This payload is then published as a message to a NATS subject that corresponds to the target queue.\nPersistence: NATS JetStream receives this message and persists it in a Stream. Each queue in naq maps directly to a JetStream Stream. This ensures that even if no workers are online, the job is safely stored and will be processed later.\nFetching: A naq worker process is constantly listening on the queue’s Stream. When a new job is available, the worker consumes the message, acknowledging it to NATS so that it isn’t delivered to another worker.\nExecution: The worker deserializes the job payload and executes the specified Python function with the provided arguments.\nResult Handling: Once the function completes, its return value is serialized. The worker then stores this result in a NATS Key-Value (KV) Store, using the unique job ID as the key. This result has a configurable Time-To-Live (TTL), after which it is automatically purged by NATS.\nScheduled Jobs: The naq scheduler process periodically scans a dedicated KV store for jobs that are due to run. When it finds one, it enqueues it into the appropriate queue, and the job follows the normal lifecycle from there."
  },
  {
    "objectID": "architecture.html#why-nats",
    "href": "architecture.html#why-nats",
    "title": "Architecture Overview",
    "section": "Why NATS?",
    "text": "Why NATS?\nUsing NATS and JetStream as the foundation provides several key advantages:\n\nDecoupling: Clients, workers, and the scheduler are completely decoupled. They only need to know how to talk to NATS, not to each other directly.\nScalability: You can add more workers at any time to increase your processing capacity. NATS handles the load balancing of jobs to available workers automatically.\nResilience: If a worker crashes, JetStream ensures that the job it was processing will be re-delivered to another worker after a timeout. If the entire naq system goes down, the jobs are safe in the NATS stream, ready to be processed when the system comes back online.\nSimplicity: By offloading the complexities of persistence, delivery guarantees, and storage to NATS, the naq codebase can remain focused on the core logic of job execution and scheduling."
  },
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installation",
    "section": "",
    "text": "You can install naq directly from PyPI using pip. A Python version of 3.12 or higher is required.\npip install naq\n\n\nFor faster installation, you can also use modern package managers like uv or pixi:\n# Using uv\nuv pip install naq\n\n# Using pixi\npixi add naq\n\n\n\nnaq comes with an optional web-based dashboard for real-time monitoring. To install the necessary dependencies (including Sanic and Datastar), use the dashboard extra:\npip install naq[dashboard]"
  },
  {
    "objectID": "installation.html#installing-naq",
    "href": "installation.html#installing-naq",
    "title": "Installation",
    "section": "",
    "text": "You can install naq directly from PyPI using pip. A Python version of 3.12 or higher is required.\npip install naq\n\n\nFor faster installation, you can also use modern package managers like uv or pixi:\n# Using uv\nuv pip install naq\n\n# Using pixi\npixi add naq\n\n\n\nnaq comes with an optional web-based dashboard for real-time monitoring. To install the necessary dependencies (including Sanic and Datastar), use the dashboard extra:\npip install naq[dashboard]"
  },
  {
    "objectID": "installation.html#setting-up-nats",
    "href": "installation.html#setting-up-nats",
    "title": "Installation",
    "section": "Setting Up NATS",
    "text": "Setting Up NATS\nnaq requires a running NATS server with JetStream enabled to function. JetStream provides the persistence layer for jobs and results.\n\nUsing Docker (Recommended)\nThe easiest way to get a NATS server running for development is by using the provided Docker Compose file.\n\nNavigate to the docker directory in the project root: bash     cd /path/to/naq/docker\nStart the NATS server in detached mode: bash     docker-compose up -d\n\nThis will start a NATS server on localhost:4222 with JetStream enabled and ready to use.\n\n\nManual Setup\nIf you prefer to run a NATS server manually, ensure that you start it with the -js flag to enable JetStream:\nnats-server -js\nRefer to the official NATS documentation for detailed installation instructions for your operating system."
  },
  {
    "objectID": "installation.html#troubleshooting",
    "href": "installation.html#troubleshooting",
    "title": "Installation",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\n\n\n\n\n\nNote\n\n\n\nConnection Issues?\n\nEnsure your NATS server is running and accessible from where you are running your application and workers.\nVerify that JetStream is enabled. You can check the server logs for a line confirming “JetStream is enabled.”\nBy default, naq attempts to connect to nats://localhost:4222. If your server is elsewhere, set the NATS_URL environment variable."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NAQ - NATS Asynchronous Queue",
    "section": "",
    "text": "NAQ is a simple, asynchronous job queueing library for Python, inspired by RQ (Redis Queue), but built entirely on top of NATS and its JetStream persistence layer.\nIt allows you to easily enqueue Python functions to be executed asynchronously by worker processes, leveraging the power and resilience of NATS JetStream for message persistence and delivery."
  },
  {
    "objectID": "index.html#get-started",
    "href": "index.html#get-started",
    "title": "NAQ - NATS Asynchronous Queue",
    "section": "Get Started",
    "text": "Get Started\nReady to dive in? Check out the Quickstart Guide to get your first worker up and running in minutes."
  },
  {
    "objectID": "index.html#key-features",
    "href": "index.html#key-features",
    "title": "NAQ - NATS Asynchronous Queue",
    "section": "Key Features",
    "text": "Key Features\n\nSimple API: Familiar and easy-to-use API, similar to RQ.\nAsynchronous Core: Built with asyncio and nats-py for high performance.\nPersistent & Reliable: Uses NATS JetStream for robust job persistence and guaranteed delivery.\nScheduled & Recurring Jobs: Supports cron-style, interval-based, and one-time scheduled tasks.\nJob Dependencies: Create complex workflows by defining dependencies between jobs.\nAutomatic Retries: Configurable retry mechanism with exponential backoff for failed jobs.\nWeb Dashboard: An optional, real-time dashboard for monitoring queues, workers, and jobs.\nCLI: A powerful command-line interface for managing your queues and workers."
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Contributing",
    "section": "",
    "text": "We welcome contributions to naq! Whether you’re fixing a bug, adding a new feature, or improving the documentation, your help is appreciated."
  },
  {
    "objectID": "contributing.html#getting-started",
    "href": "contributing.html#getting-started",
    "title": "Contributing",
    "section": "Getting Started",
    "text": "Getting Started\nIf you’re new to the project, a good place to start is by looking at the open issues on GitHub.\n\nDevelopment Setup\nTo get your development environment set up, follow these steps:\n\nFork and Clone the Repository\nStart by forking the main repository on GitHub, and then clone your fork locally:\ngit clone https://github.com/YOUR_USERNAME/naq.git\ncd naq\nInstall Dependencies\nWe recommend using a virtual environment. naq uses uv for dependency management.\n# Create a virtual environment\npython -m venv .venv\nsource .venv/bin/activate\n\n# Install dependencies, including development tools\nuv pip install -e \".[dev]\"\nRun the NATS Server\nThe test suite and examples require a running NATS server. You can use the provided Docker Compose file:\ncd docker\ndocker-compose up -d\nRun the Tests\nTo make sure everything is set up correctly, run the test suite:\npytest"
  },
  {
    "objectID": "contributing.html#making-changes",
    "href": "contributing.html#making-changes",
    "title": "Contributing",
    "section": "Making Changes",
    "text": "Making Changes\n\nCreate a New Branch\nCreate a new branch for your changes:\ngit checkout -b feature/my-new-feature\nWrite Your Code\nMake your changes to the codebase. If you’re adding a new feature, please include tests.\nFormat Your Code\nBefore committing, make sure your code is formatted correctly:\nruff format .\nruff check --fix .\nCommit and Push\nCommit your changes with a clear and descriptive message, and push them to your fork:\ngit commit -m \"feat: Add my new feature\"\ngit push origin feature/my-new-feature\nCreate a Pull Request\nOpen a pull request from your fork to the main branch of the naq repository. Provide a clear description of your changes and reference any related issues."
  },
  {
    "objectID": "contributing.html#code-of-conduct",
    "href": "contributing.html#code-of-conduct",
    "title": "Contributing",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nPlease note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms.\nThank you for contributing to naq!"
  },
  {
    "objectID": "quickstart.html",
    "href": "quickstart.html",
    "title": "Quickstart Guide",
    "section": "",
    "text": "This guide will walk you through the basics of setting up a task, enqueuing it, and running a worker to process it."
  },
  {
    "objectID": "quickstart.html#define-a-task",
    "href": "quickstart.html#define-a-task",
    "title": "Quickstart Guide",
    "section": "1. Define a Task",
    "text": "1. Define a Task\nFirst, create a Python file to define the function you want to run in the background. Let’s call this file tasks.py.\nThis function can be any regular Python function. For this example, we’ll create a simple function that simulates some work and counts the words in a given text.\n# tasks.py\nimport time\nimport random\n\ndef count_words(text):\n    \"\"\"\n    A simple function that counts the words in a string.\n    \"\"\"\n    print(f\"Processing text: '{text[:30]}...'\")\n    # Simulate some I/O or CPU-bound work\n    time.sleep(random.randint(1, 3))\n    word_count = len(text.split())\n    print(f\"Found {word_count} words.\")\n    return word_count"
  },
  {
    "objectID": "quickstart.html#enqueue-the-job",
    "href": "quickstart.html#enqueue-the-job",
    "title": "Quickstart Guide",
    "section": "2. Enqueue the Job",
    "text": "2. Enqueue the Job\nNow, let’s enqueue the count_words function to be executed by a worker. Create another file, main.py, to send the job to the queue.\nWe’ll use the enqueue_sync function, which is a simple, blocking way to add a job to the queue.\n# main.py\nfrom naq import enqueue_sync\nfrom tasks import count_words\n\n# The text we want to process\nlong_text = (\n    \"A journey of a thousand miles begins with a single step. \"\n    \"The best time to plant a tree was 20 years ago. \"\n    \"The second best time is now.\"\n)\n\nprint(\"Enqueuing job to count words...\")\n\n# Enqueue the function `count_words` with `long_text` as its argument\njob = enqueue_sync(count_words, long_text)\n\nprint(f\"Successfully enqueued job {job.job_id}.\")\nprint(\"To process the job, run a worker with: naq worker default\")"
  },
  {
    "objectID": "quickstart.html#run-the-worker",
    "href": "quickstart.html#run-the-worker",
    "title": "Quickstart Guide",
    "section": "3. Run the Worker",
    "text": "3. Run the Worker\nWith the job enqueued, the final step is to start a worker process. The worker will connect to NATS, fetch the job from the queue, and execute the count_words function.\nOpen your terminal and run the following command:\nnaq worker default\nThe default argument tells the worker to listen to the default queue, which is where enqueue_sync sends jobs.\nYou should see output similar to this in your worker’s terminal:\n14:30:15.123 INFO     Worker listening on queue: naq_default_queue\nProcessing text: 'A journey of a thousand miles...'\nFound 25 words.\n14:30:18.245 INFO     Job 1a2b3c4d completed. Result: 25\nCongratulations! You’ve successfully enqueued and processed your first background job with naq."
  },
  {
    "objectID": "quickstart.html#whats-next",
    "href": "quickstart.html#whats-next",
    "title": "Quickstart Guide",
    "section": "What’s Next?",
    "text": "What’s Next?\n\nExplore how to schedule jobs to run in the future.\nLearn about the architecture of naq.\nCheck out more complex examples."
  },
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "Usage Examples",
    "section": "",
    "text": "This page provides practical examples for some of naq’s key features."
  },
  {
    "objectID": "examples.html#example-1-scheduled-and-recurring-jobs",
    "href": "examples.html#example-1-scheduled-and-recurring-jobs",
    "title": "Usage Examples",
    "section": "Example 1: Scheduled and Recurring Jobs",
    "text": "Example 1: Scheduled and Recurring Jobs\nnaq allows you to schedule jobs to run at a specific time in the future or on a recurring basis using cron expressions.\nTo run these examples, you need both a worker and the scheduler process running:\n# Terminal 1: Start the scheduler\nnaq scheduler\n\n# Terminal 2: Start a worker\nnaq worker scheduled_queue\n\nOne-Time Scheduled Job\nYou can enqueue a job to run after a specific delay or at a precise time.\n# schedule_task.py\nimport asyncio\nfrom datetime import datetime, timedelta\nfrom naq import enqueue_at, enqueue_in\n\nasync def send_reminder(user_id, message):\n    print(f\"Sending reminder to {user_id}: {message}\")\n    # Add logic to send an email or push notification\n    return f\"Reminder sent to {user_id}\"\n\nasync def main():\n    # Schedule a job to run in 5 minutes\n    run_in_5_min = await enqueue_in(\n        send_reminder,\n        delay=timedelta(minutes=5),\n        user_id=\"user123\",\n        message=\"Your meeting starts in 5 minutes.\",\n        queue_name=\"scheduled_queue\"\n    )\n    print(f\"Job {run_in_5_min.job_id} scheduled to run in 5 minutes.\")\n\n    # Schedule a job to run at a specific time (UTC)\n    run_at_time = datetime.utcnow() + timedelta(hours=1)\n    run_at = await enqueue_at(\n        send_reminder,\n        run_at=run_at_time,\n        user_id=\"user456\",\n        message=\"Don't forget your 1-hour follow-up.\",\n        queue_name=\"scheduled_queue\"\n    )\n    print(f\"Job {run_at.job_id} scheduled to run at {run_at_time.isoformat()}.\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n\nRecurring Job (Cron)\nFor tasks that need to run on a regular schedule (e.g., nightly reports, weekly cleanups), you can use the schedule function with a cron string.\n# recurring_task.py\nimport asyncio\nfrom naq import schedule\n\nasync def generate_nightly_report():\n    print(\"Generating the nightly sales report...\")\n    # Logic to aggregate data and create a report\n    print(\"Nightly report complete.\")\n    return \"Report generated successfully.\"\n\nasync def main():\n    # Schedule the report to run every day at 2:00 AM UTC\n    cron_schedule = await schedule(\n        generate_nightly_report,\n        cron=\"0 2 * * *\",  # Standard cron format\n        schedule_id=\"nightly-sales-report\",\n        queue_name=\"scheduled_queue\"\n    )\n    print(f\"Cron job '{cron_schedule.schedule_id}' is now active.\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())"
  },
  {
    "objectID": "examples.html#example-2-automatic-job-retries",
    "href": "examples.html#example-2-automatic-job-retries",
    "title": "Usage Examples",
    "section": "Example 2: Automatic Job Retries",
    "text": "Example 2: Automatic Job Retries\nnaq can automatically retry failed jobs with configurable strategies. This is useful for tasks that might fail due to transient issues, like network hiccups.\n# retry_task.py\nimport asyncio\nimport random\nfrom naq import enqueue\n\nasync def flaky_api_call(request_id):\n    \"\"\"\n    This function simulates an API call that sometimes fails.\n    \"\"\"\n    print(f\"Attempting to call API for request {request_id}...\")\n    if random.random() &gt; 0.5:\n        print(\"API call successful!\")\n        return \"Success\"\n    else:\n        print(\"API call failed. Will retry...\")\n        raise ConnectionError(\"Could not connect to the API\")\n\nasync def main():\n    # Enqueue the job with a retry policy\n    job = await enqueue(\n        flaky_api_call,\n        request_id=\"abc-123\",\n        queue_name=\"default\",\n        max_retries=3,          # Attempt the job up to 3 more times\n        retry_delay=5,          # Wait 5 seconds between retries\n        retry_strategy=\"linear\" # Use a fixed delay\n    )\n    print(f\"Enqueued job {job.job_id} with 3 linear retries.\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n\n\n\n\n\nNote\n\n\n\nRetry Strategies\nnaq supports both linear (fixed delay) and exponential backoff strategies for retries. You can also provide a list of integers to retry_delay for a custom delay sequence."
  },
  {
    "objectID": "examples.html#example-3-job-dependencies",
    "href": "examples.html#example-3-job-dependencies",
    "title": "Usage Examples",
    "section": "Example 3: Job Dependencies",
    "text": "Example 3: Job Dependencies\nYou can create workflows by making jobs dependent on the successful completion of others. The dependent job will only run after its dependencies have finished.\n# dependency_workflow.py\nimport asyncio\nfrom naq import enqueue\n\nasync def download_data(source_url):\n    print(f\"Downloading data from {source_url}...\")\n    await asyncio.sleep(2)  # Simulate download\n    file_path = f\"/tmp/{source_url.split('/')[-1]}.csv\"\n    print(f\"Data downloaded to {file_path}\")\n    return file_path\n\nasync def process_data(file_path):\n    print(f\"Processing data from {file_path}...\")\n    await asyncio.sleep(3)  # Simulate processing\n    result_path = f\"{file_path}.processed\"\n    print(f\"Data processed and saved to {result_path}\")\n    return result_path\n\nasync def upload_results(result_path):\n    print(f\"Uploading {result_path} to cloud storage...\")\n    await asyncio.sleep(1)  # Simulate upload\n    print(\"Upload complete.\")\n    return \"Workflow finished successfully.\"\n\nasync def main():\n    # Step 1: Download data\n    download_job = await enqueue(download_data, source_url=\"http://example.com/data\")\n\n    # Step 2: Process data (depends on download)\n    process_job = await enqueue(\n        process_data,\n        file_path=download_job, # Pass the result of the dependency\n        depends_on=[download_job]\n    )\n\n    # Step 3: Upload results (depends on processing)\n    upload_job = await enqueue(\n        upload_results,\n        result_path=process_job,\n        depends_on=[process_job]\n    )\n\n    print(f\"Workflow started. Final job: {upload_job.job_id}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())"
  },
  {
    "objectID": "examples.html#example-4-using-multiple-queues",
    "href": "examples.html#example-4-using-multiple-queues",
    "title": "Usage Examples",
    "section": "Example 4: Using Multiple Queues",
    "text": "Example 4: Using Multiple Queues\nYou can use different queues to prioritize jobs or to dedicate workers to specific types of tasks.\nStart workers for each queue in separate terminals:\n# Terminal 1: High-priority worker\nnaq worker notifications --log-level info\n\n# Terminal 2: Low-priority worker\nnaq worker data_processing --log-level info\nNow, you can enqueue jobs to the appropriate queues.\n```python # multi_queue_example.py import asyncio from naq import enqueue\nasync def send_email(address, subject, body): print(f”Sending high-priority email to {address}…“) await asyncio.sleep(0.5) return”Email sent.”\nasync def transcode_video(video_id): print(f”Starting low-priority video transcoding for {video_id}…“) await asyncio.sleep(10) # Simulate long-running task return”Video transcoded.”\nasync def main(): # Enqueue a high-priority job email_job = await enqueue( send_email, address=“user@example.com”, subject=“Your order”, body=“…”, queue_name=“notifications” # Target the ‘notifications’ queue ) print(f”Enqueued notification job {email_job.job_id}“)\n# Enqueue a low-priority job\nvideo_job = await enqueue(\n    transcode_video,\n    video_id=12345,\n    queue_name=\"data_processing\" # Target the 'data_processing' queue\n)\nprint(f\"Enqueued data processing job {video_job.job_id}\")\nif name == “main”: asyncio.run(main())"
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "API Reference",
    "section": "",
    "text": "This section provides a detailed reference for the public API of the naq library.\nThe API is organized into modules, each providing specific functionality."
  },
  {
    "objectID": "api/index.html#core-modules",
    "href": "api/index.html#core-modules",
    "title": "API Reference",
    "section": "Core Modules",
    "text": "Core Modules\n\nqueue Module: The primary interface for enqueuing and scheduling jobs. Includes the Queue class and helper functions like enqueue, enqueue_at, and schedule.\njob Module: Defines the Job class, which represents a unit of work to be executed.\nworker Module: Contains the Worker class, responsible for executing jobs from one or more queues.\nscheduler Module: Contains the Scheduler class, responsible for enqueuing scheduled and recurring jobs.\nexceptions Module: Defines custom exceptions raised by naq."
  },
  {
    "objectID": "api/job.html",
    "href": "api/job.html",
    "title": "Job API",
    "section": "",
    "text": "The Job class represents a unit of work that is enqueued and executed by a worker. You typically don’t create Job instances directly; they are created for you when you call functions like naq.enqueue().\nA Job instance is returned every time you enqueue a task, and it serves as a handle to that task."
  },
  {
    "objectID": "api/job.html#naq.job.job",
    "href": "api/job.html#naq.job.job",
    "title": "Job API",
    "section": "naq.job.Job",
    "text": "naq.job.Job\n\nProperties\n\n\n\n\n\n\n\n\nProperty\nType\nDescription\n\n\n\n\njob_id\nstr\nA unique identifier for the job.\n\n\nfunction\nCallable\nThe function that will be executed.\n\n\nargs\ntuple\nThe positional arguments passed to the function.\n\n\nkwargs\ndict\nThe keyword arguments passed to the function.\n\n\nqueue_name\nstr\nThe name of the queue the job belongs to.\n\n\nstatus\nJOB_STATUS\nThe current status of the job (pending, running, completed, failed).\n\n\nmax_retries\nint\nThe maximum number of times the job will be retried if it fails.\n\n\nretry_delay\nint | float | list\nThe delay (in seconds) between retries. Can be a single value or a list.\n\n\nretry_strategy\nstr\nThe retry strategy (linear or exponential).\n\n\ndepends_on\nlist[str] | None\nA list of job IDs that this job depends on.\n\n\nresult_ttl\nint | None\nThe time-to-live (in seconds) for the job’s result.\n\n\ntimeout\nint | None\nThe maximum time (in seconds) the job is allowed to run.\n\n\nenqueue_time\nfloat\nThe timestamp when the job was enqueued.\n\n\nerror\nstr | None\nThe error message if the job failed.\n\n\ntraceback\nstr | None\nThe traceback if the job failed.\n\n\n\n\n\nMethods\n\nfetch_result()\nA static method to fetch the result of a completed job.\n@staticmethod\nasync def fetch_result(job_id: str, nats_url: str = DEFAULT_NATS_URL) -&gt; Any\n\n\n\n\n\n\n\n\nParameter\nType\nDescription\n\n\n\n\njob_id\nstr\nThe ID of the job whose result you want to fetch.\n\n\nnats_url\nstr\nThe URL of the NATS server.\n\n\n\nReturns: The return value of the job’s function.\nRaises:\n\nJobNotFoundError: If the job result is not found (it may not have completed, or the result may have expired).\nJobExecutionError: If the job failed. The exception message will contain the error and traceback from the worker.\n\n\n\nfetch_result_sync()\nA synchronous version of fetch_result().\n\n\n\n\n\n\nNote\n\n\n\nfetch_result_sync is deprecated and will be removed in a future version. Please use fetch_result in an async context."
  },
  {
    "objectID": "api/scheduler.html",
    "href": "api/scheduler.html",
    "title": "Scheduler API",
    "section": "",
    "text": "The scheduler module contains the Scheduler class, which is responsible for finding and enqueuing scheduled and recurring jobs."
  },
  {
    "objectID": "api/scheduler.html#naq.scheduler.scheduler",
    "href": "api/scheduler.html#naq.scheduler.scheduler",
    "title": "Scheduler API",
    "section": "naq.scheduler.Scheduler",
    "text": "naq.scheduler.Scheduler\nYou typically run the scheduler from the command line using naq scheduler, but you can also create and run a Scheduler instance programmatically.\n\nnaq.scheduler.Scheduler(nats_url, poll_interval, instance_id, enable_ha)\n\n\n\n\n\n\n\n\nParameter\nType\nDescription\n\n\n\n\nnats_url\nstr\nThe URL of the NATS server.\n\n\npoll_interval\nfloat\nThe interval (in seconds) at which the scheduler checks for due jobs. Defaults to 1.0.\n\n\ninstance_id\nstr | None\nA unique ID for the scheduler instance, used for High Availability. A unique ID is generated if not provided.\n\n\nenable_ha\nbool\nWhether to enable High Availability (HA) mode with leader election. Defaults to True.\n\n\n\n\n\nMethods\n\nrun()\nStarts the scheduler’s main processing loop. This is an async method.\nasync def run(self) -&gt; None\nThe scheduler will connect to NATS and, if it becomes the leader (or if HA is disabled), it will start polling for jobs that are ready to be enqueued.\n\n\n\nHigh Availability (HA)\nWhen enable_ha is True, you can run multiple Scheduler instances for redundancy. They will use a leader election protocol built on a NATS KV store to ensure that only one instance is actively scheduling jobs at any given time. If the leader instance goes down, another instance will automatically take over."
  }
]