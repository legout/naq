---
title: "Usage Examples"
---

This page provides practical examples for some of `naq`'s key features.

## Example 1: Scheduled and Recurring Jobs

`naq` allows you to schedule jobs to run at a specific time in the future or on a recurring basis using cron expressions.

To run these examples, you need both a worker and the scheduler process running:

```bash
# Terminal 1: Start the scheduler
naq scheduler

# Terminal 2: Start a worker
naq worker scheduled_queue
```

### One-Time Scheduled Job

You can enqueue a job to run after a specific delay or at a precise time.

```python
# schedule_task.py
import asyncio
from datetime import datetime, timedelta
from naq import enqueue_at, enqueue_in

async def send_reminder(user_id, message):
    print(f"Sending reminder to {user_id}: {message}")
    # Add logic to send an email or push notification
    return f"Reminder sent to {user_id}"

async def main():
    # Schedule a job to run in 5 minutes
    run_in_5_min = await enqueue_in(
        send_reminder,
        delay=timedelta(minutes=5),
        user_id="user123",
        message="Your meeting starts in 5 minutes.",
        queue_name="scheduled_queue"
    )
    print(f"Job {run_in_5_min.job_id} scheduled to run in 5 minutes.")

    # Schedule a job to run at a specific time (UTC)
    run_at_time = datetime.utcnow() + timedelta(hours=1)
    run_at = await enqueue_at(
        send_reminder,
        run_at=run_at_time,
        user_id="user456",
        message="Don't forget your 1-hour follow-up.",
        queue_name="scheduled_queue"
    )
    print(f"Job {run_at.job_id} scheduled to run at {run_at_time.isoformat()}.")

if __name__ == "__main__":
    asyncio.run(main())
```

### Recurring Job (Cron)

For tasks that need to run on a regular schedule (e.g., nightly reports, weekly cleanups), you can use the `schedule` function with a cron string.

```python
# recurring_task.py
import asyncio
from naq import schedule

async def generate_nightly_report():
    print("Generating the nightly sales report...")
    # Logic to aggregate data and create a report
    print("Nightly report complete.")
    return "Report generated successfully."

async def main():
    # Schedule the report to run every day at 2:00 AM UTC
    cron_schedule = await schedule(
        generate_nightly_report,
        cron="0 2 * * *",  # Standard cron format
        schedule_id="nightly-sales-report",
        queue_name="scheduled_queue"
    )
    print(f"Cron job '{cron_schedule.schedule_id}' is now active.")

if __name__ == "__main__":
    asyncio.run(main())
```

## Example 2: Automatic Job Retries

`naq` can automatically retry failed jobs with configurable strategies. This is useful for tasks that might fail due to transient issues, like network hiccups.

```python
# retry_task.py
import asyncio
import random
from naq import enqueue

async def flaky_api_call(request_id):
    """
    This function simulates an API call that sometimes fails.
    """
    print(f"Attempting to call API for request {request_id}...")
    if random.random() > 0.5:
        print("API call successful!")
        return "Success"
    else:
        print("API call failed. Will retry...")
        raise ConnectionError("Could not connect to the API")

async def main():
    # Enqueue the job with a retry policy
    job = await enqueue(
        flaky_api_call,
        request_id="abc-123",
        queue_name="default",
        max_retries=3,          # Attempt the job up to 3 more times
        retry_delay=5,          # Wait 5 seconds between retries
        retry_strategy="linear" # Use a fixed delay
    )
    print(f"Enqueued job {job.job_id} with 3 linear retries.")

if __name__ == "__main__":
    asyncio.run(main())
```

::: {.callout-note}
**Retry Strategies**

`naq` supports both `linear` (fixed delay) and `exponential` backoff strategies for retries. You can also provide a list of integers to `retry_delay` for a custom delay sequence.
:::

## Example 3: Job Dependencies

You can create workflows by making jobs dependent on the successful completion of others. The dependent job will only run after its dependencies have finished.

```python
# dependency_workflow.py
import asyncio
from naq import enqueue

async def download_data(source_url):
    print(f"Downloading data from {source_url}...")
    await asyncio.sleep(2)  # Simulate download
    file_path = f"/tmp/{source_url.split('/')[-1]}.csv"
    print(f"Data downloaded to {file_path}")
    return file_path

async def process_data(file_path):
    print(f"Processing data from {file_path}...")
    await asyncio.sleep(3)  # Simulate processing
    result_path = f"{file_path}.processed"
    print(f"Data processed and saved to {result_path}")
    return result_path

async def upload_results(result_path):
    print(f"Uploading {result_path} to cloud storage...")
    await asyncio.sleep(1)  # Simulate upload
    print("Upload complete.")
    return "Workflow finished successfully."

async def main():
    # Step 1: Download data
    download_job = await enqueue(download_data, source_url="http://example.com/data")

    # Step 2: Process data (depends on download)
    process_job = await enqueue(
        process_data,
        file_path=download_job, # Pass the result of the dependency
        depends_on=[download_job]
    )

    # Step 3: Upload results (depends on processing)
    upload_job = await enqueue(
        upload_results,
        result_path=process_job,
        depends_on=[process_job]
    )

    print(f"Workflow started. Final job: {upload_job.job_id}")

if __name__ == "__main__":
    asyncio.run(main())
```

## Example 4: Using Multiple Queues

You can use different queues to prioritize jobs or to dedicate workers to specific types of tasks.

Start workers for each queue in separate terminals:

```bash
# Terminal 1: High-priority worker
naq worker notifications --log-level info

# Terminal 2: Low-priority worker
naq worker data_processing --log-level info
```

Now, you can enqueue jobs to the appropriate queues.

```python
# multi_queue_example.py
import asyncio
from naq import enqueue

async def send_email(address, subject, body):
    print(f"Sending high-priority email to {address}...")
    await asyncio.sleep(0.5)
    return "Email sent."

async def transcode_video(video_id):
    print(f"Starting low-priority video transcoding for {video_id}...")
    await asyncio.sleep(10) # Simulate long-running task
    return "Video transcoded."

async def main():
    # Enqueue a high-priority job
    email_job = await enqueue(
        send_email,
        address="user@example.com",
        subject="Your order",
        body="...",
        queue_name="notifications" # Target the 'notifications' queue
    )
    print(f"Enqueued notification job {email_job.job_id}")

    # Enqueue a low-priority job
    video_job = await enqueue(
        transcode_video,
        video_id=12345,
        queue_name="data_processing" # Target the 'data_processing' queue
    )
    print(f"Enqueued data processing job {video_job.job_id}")

if __name__ == "__main__":
    asyncio.run(main())