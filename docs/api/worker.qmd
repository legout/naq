---
title: "Worker API"
---

The `worker` module contains the `Worker` class, which is responsible for fetching and executing jobs from one or more queues.

## `naq.worker.Worker`

You can start a worker from the command line using `naq worker`, but you can also create and run a `Worker` instance programmatically.

### `naq.worker.Worker(queues, config=None, services=None, ...)`

The `Worker` class constructor now prioritizes the `config` and `services` parameters for centralized configuration and dependency injection. Parameters like `nats_url`, `heartbeat_interval`, `worker_ttl`, `ack_wait`, and `module_paths` are now typically managed via the `config` object or internally by the service layer.

| Parameter            | Type                               | Description                                                                                             |
| -------------------- | ---------------------------------- | ------------------------------------------------------------------------------------------------------- |
| `queues`             | `list[str]` &#124; `str`            | A list of queue names to listen to. Defaults to the single `naq_default_queue`.                         |
| `config`             | `NAQConfig` &#124; `dict` &#124; `None` | Optional NAQConfig object or dictionary for worker and service configuration.                           |
| `services`           | `ServiceManager` &#124; `None`     | Optional ServiceManager instance for dependency injection.                                               |
| `concurrency`        | `int`                              | The maximum number of jobs to process concurrently. Defaults to `10`.                                     |
| `worker_name`        | `str` &#124; `None`                 | A name for the worker, used for creating durable consumer names. A unique ID is generated if not provided. |
| `nats_url`           | `str`                              | *Deprecated.* The URL of the NATS server. Use `config` instead.                                         |
| `heartbeat_interval` | `int`                              | *Deprecated.* The interval (in seconds) at which the worker sends a heartbeat. Use `config` instead.    |
| `worker_ttl`         | `int`                              | *Deprecated.* The time-to-live (in seconds) for the worker's heartbeat. Use `config` instead.           |
| `ack_wait`           | `int` &#124; `dict` &#124; `None`   | *Deprecated.* The time (in seconds) the worker has to acknowledge a job. Use `config` instead.          |
| `module_paths`       | `list[str]` &#124; `str` &#124; `None` | *Deprecated.* Paths to add to `sys.path`. Use `config` instead.                                         |


### Methods

#### `run()`

Starts the worker's main processing loop. This method internally uses `JobService` for job execution and `EventService` for logging job events.

```python
async def run(self) -> None
```

The worker will connect to NATS, subscribe to the specified queues, and start fetching jobs. It will run until a shutdown signal is received.

#### `run_sync()`

A synchronous method to start the worker. This is useful when running a worker from a synchronous script.

```python
def run_sync(self) -> None
```

This method will block until the worker is shut down.

#### `list_workers()`

A static method to list all active workers.

```python
@staticmethod
async def list_workers(nats_url: str = DEFAULT_NATS_URL) -> list[dict]
```

Returns a list of dictionaries, where each dictionary contains information about a worker (ID, status, hostname, etc.).

#### `list_workers_sync()`

A synchronous version of `list_workers()`.

## Service Layer Integration

The `Worker` class integrates with the service layer architecture to provide efficient resource management and connection pooling. When using the service layer, the worker automatically leverages centralized services for NATS connections, job execution, and event logging.

### Worker Class Definition and Service Layer Integration

The `Worker` class is designed to seamlessly integrate with NAQ's service layer, allowing it to leverage shared resources and centralized configuration.

```python
from naq.config import NAQConfig
from naq.services import ServiceManager, JobService, EventService, ConnectionService
from naq.worker.core import Worker as CoreWorker
from typing import List, Optional, Union, Dict, Any
import asyncio

class Worker(CoreWorker):
    def __init__(
        self,
        queues: Union[str, List[str]],
        config: Optional[Union[NAQConfig, dict]] = None,
        services: Optional[ServiceManager] = None,
        concurrency: int = 10,
        worker_name: Optional[str] = None,
        # Deprecated parameters (managed by config or services)
        nats_url: Optional[str] = None,
        heartbeat_interval: Optional[int] = None,
        worker_ttl: Optional[int] = None,
        ack_wait: Optional[Union[int, Dict[str, int]]] = None,
        module_paths: Optional[Union[str, List[str]]] = None,
    ):
        super().__init__(
            queues=queues,
            config=config,
            services=services,
            concurrency=concurrency,
            worker_name=worker_name,
            nats_url=nats_url, # Passed for backward compatibility within core
            heartbeat_interval=heartbeat_interval,
            worker_ttl=worker_ttl,
            ack_wait=ack_wait,
            module_paths=module_paths,
        )
        self._job_service: Optional[JobService] = None
        self._event_service: Optional[EventService] = None
        self._connection_service: Optional[ConnectionService] = None

    async def _setup_services(self):
        """Internal method to get service instances from ServiceManager."""
        if self._services:
            self._job_service = await self._services.get_service(JobService)
            self._event_service = await self._services.get_service(EventService)
            self._connection_service = await self._services.get_service(ConnectionService)

    async def run(self) -> None:
        """
        Starts the worker's main processing loop.
        This method now leverages JobService for job execution and EventService for event logging.
        """
        await self._setup_services() # Ensure services are available
        # The core run logic will then use self._job_service and self._event_service
        # for processing jobs and logging events.
        await super().run() # Call the original run method from CoreWorker

```

#### Usage Pattern with `ServiceManager`

The recommended way to instantiate and run a `Worker` is by providing a `ServiceManager` instance. This allows the `Worker` to share and leverage the common services managed by the `ServiceManager`.


```python
import asyncio
from naq.worker import Worker
from naq.services import ServiceManager

async def worker_with_services():
    # Create service configuration
    config = {
        'nats': {
            'url': 'nats://localhost:4222',
            'max_reconnect_attempts': 5,
            'reconnect_delay': 1.0
        },
        'jobs': {
            'default_timeout': 3600,
            'result_ttl': 604800
        },
        'events': {
            'enabled': True,
            'batch_size': 100,
            'flush_interval': 1.0
        }
    }
    
    # Use ServiceManager for lifecycle management
    async with ServiceManager(config) as services:
        # Create Worker with ServiceManager
        worker = Worker(
            queues=['high_priority', 'low_priority'],
            services=services,
            concurrency=5
        )
        
        # Run the worker - it will automatically use the services
        await worker.run()
        
        # Services are automatically managed and cleaned up
```

### Benefits of Service Layer Integration

1. **Connection Pooling**: Multiple workers can share the same NATS connection, reducing resource usage.

2. **Centralized Job Execution**: Job execution is handled by the JobService, providing consistent error handling and result management.

3. **Event Logging**: Worker events are automatically logged through the EventService, providing comprehensive monitoring.

4. **Automatic Resource Management**: Services are automatically initialized and cleaned up by the ServiceManager.

### Migration from Direct Connection Management

#### Before (Direct Connection Management)

```python
# Old approach - direct connection management
async def old_worker_usage():
    worker = Worker(
        queues=['example'],
        nats_url='nats://localhost:4222',
        concurrency=10
    )
    
    try:
        await worker.run()
    finally:
        # Manual cleanup was required
        pass
```

#### After (Service Layer)

```python
# New approach - service layer
async def new_worker_usage():
    config = {'nats': {'url': 'nats://localhost:4222'}}
    
    async with ServiceManager(config) as services:
        worker = Worker(
            queues=['example'],
            services=services,
            concurrency=10
        )
        
        await worker.run()
        # No need to manually manage connections - services are automatically managed
```

### Advanced Service Configuration

You can provide detailed configuration for the services used by the worker:

```python
async def advanced_worker_config():
    config = {
        'nats': {
            'url': 'nats://localhost:4222',
            'max_reconnect_attempts': 10,
            'reconnect_delay': 2.0,
            'connection_timeout': 30.0
        },
        'jobs': {
            'default_timeout': 3600,
            'result_ttl': 604800,
            'cleanup_interval': 3600  # Clean up old results every hour
        },
        'events': {
            'enabled': True,
            'batch_size': 100,
            'flush_interval': 1.0,
            'max_buffer_size': 10000
        }
    }
    
    async with ServiceManager(config) as services:
        worker = Worker(
            queues=['production'],
            services=services,
            concurrency=20,
            worker_name='production-worker-1'
        )
        
        await worker.run()
```

### Sharing ServiceManager Across Workers

Multiple workers can share the same ServiceManager for efficient resource usage:

```python
async def shared_worker_services():
    config = {'nats': {'url': 'nats://localhost:4222'}}
    
    async with ServiceManager(config) as services:
        # Create multiple workers sharing the same services
        worker1 = Worker(
            queues=['high_priority'],
            services=services,
            concurrency=5,
            worker_name='high-priority-worker'
        )
        
        worker2 = Worker(
            queues=['low_priority'],
            services=services,
            concurrency=10,
            worker_name='low-priority-worker'
        )
        
        # Run workers concurrently
        worker1_task = asyncio.create_task(worker1.run())
        worker2_task = asyncio.create_task(worker2.run())
        
        # Wait for both workers (in a real scenario, you might run them indefinitely)
        await asyncio.sleep(10)
        
        # Cancel worker tasks
        worker1_task.cancel()
        worker2_task.cancel()
        
        try:
            await worker1_task
            await worker2_task
        except asyncio.CancelledError:
            pass
```

### Worker Event Integration

When using the service layer, workers automatically integrate with the event system:

```python
async def worker_with_events():
    config = {
        'nats': {'url': 'nats://localhost:4222'},
        'events': {
            'enabled': True,
            'batch_size': 50,
            'flush_interval': 0.5
        }
    }
    
    async with ServiceManager(config) as services:
        worker = Worker(
            queues=['example'],
            services=services,
            concurrency=3
        )
        
        # The worker will automatically log:
        # - STARTED events when jobs begin processing
        # - COMPLETED events when jobs finish successfully
        # - FAILED events when jobs encounter errors
        # - STATUS_CHANGED events for job state transitions
        
        await worker.run()
```

### Custom Worker with Services

For advanced use cases, you can create custom worker classes that leverage the service layer:

```python
from naq.worker import Worker
from naq.services import ServiceManager, JobService, EventService

class CustomWorker(Worker):
    """Custom worker with enhanced service integration."""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._job_service = None
        self._event_service = None
    
    async def _setup_services(self):
        """Set up service references."""
        if self._services:
            self._job_service = await self._services.get_service(JobService)
            self._event_service = await self._services.get_service(EventService)
    
    async def process_job(self, job):
        """Override to add custom processing with services."""
        await self._setup_services()
        
        # Log custom event before processing
        if self._event_service:
            from naq.models import JobEvent, JobEventType
            custom_event = JobEvent(
                job_id=job.job_id,
                event_type="custom_processing_started",
                queue_name=job.queue_name,
                worker_id=self.worker_name,
                details={"custom_data": "pre-processing"}
            )
            await self._event_service.log_event(custom_event)
        
        # Process the job using the job service
        result = await self._job_service.execute_job(job)
        
        # Log custom event after processing
        if self._event_service:
            custom_event = JobEvent(
                job_id=job.job_id,
                event_type="custom_processing_completed",
                queue_name=job.queue_name,
                worker_id=self.worker_name,
                details={"duration_ms": result.duration_ms}
            )
            await self._event_service.log_event(custom_event)
        
        return result

# Using the custom worker
async def custom_worker_example():
    config = {'nats': {'url': 'nats://localhost:4222'}}
    
    async with ServiceManager(config) as services:
        worker = CustomWorker(
            queues=['example'],
            services=services,
            concurrency=2
        )
        
        await worker.run()
```

The service layer integration provides a robust foundation for building efficient, maintainable worker applications with `naq`, eliminating connection duplication and providing clean resource management throughout the system.