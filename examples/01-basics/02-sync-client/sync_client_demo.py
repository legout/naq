#!/usr/bin/env python3
"""
NAQ SyncClient Demo

This example demonstrates the efficient SyncClient for batch operations.
SyncClient reuses NATS connections, providing better performance than
individual sync calls.

Before running:
1. Start NATS: `cd docker && docker-compose up -d`
2. Set secure serializer: `export NAQ_JOB_SERIALIZER=json`
3. Start workers: `naq worker default batch_jobs`
4. Run this script: `python sync_client_demo.py`
"""

import os
import time
from datetime import datetime, timedelta, timezone
from typing import List

# Import NAQ components
from naq import SyncClient, enqueue_sync, setup_logging

# Configure secure JSON serialization
os.environ.setdefault('NAQ_JOB_SERIALIZER', 'json')

# Setup logging
setup_logging(level="INFO")


def process_data(data_id: int, category: str = "general") -> str:
    """
    Simulate data processing task.
    
    Args:
        data_id: Unique identifier for the data
        category: Category of data being processed
        
    Returns:
        Processing result message
    """
    print(f"üîÑ Processing {category} data {data_id}")
    time.sleep(1)  # Simulate work
    result = f"Processed {category} data {data_id}"
    print(f"‚úÖ {result}")
    return result


def send_notification(user_id: str, message: str) -> str:
    """
    Simulate sending a notification.
    
    Args:
        user_id: Target user ID
        message: Notification message
        
    Returns:
        Delivery confirmation
    """
    print(f"üìß Sending notification to {user_id}: {message}")
    time.sleep(0.5)  # Simulate quick notification
    result = f"Notification sent to {user_id}"
    print(f"‚úÖ {result}")
    return result


def generate_report(report_type: str, date: str) -> str:
    """
    Simulate report generation.
    
    Args:
        report_type: Type of report to generate
        date: Date for the report
        
    Returns:
        Report generation result
    """
    print(f"üìä Generating {report_type} report for {date}")
    time.sleep(2)  # Simulate longer processing
    result = f"{report_type} report for {date} completed"
    print(f"‚úÖ {result}")
    return result


def performance_test():
    """
    Compare performance between individual sync calls and SyncClient.
    """
    print("üìä Performance Test: Enqueueing 10 jobs")
    print("-" * 40)
    
    # Test without SyncClient (inefficient)
    start_time = time.time()
    
    jobs_individual = []
    for i in range(10):
        job = enqueue_sync(
            process_data,
            data_id=i,
            category="performance_test",
            queue_name="batch_jobs"
        )
        jobs_individual.append(job)
    
    individual_time = time.time() - start_time
    
    # Test with SyncClient (efficient)
    start_time = time.time()
    
    jobs_batch = []
    with SyncClient() as client:
        for i in range(10, 20):  # Different IDs to avoid confusion
            job = client.enqueue(
                process_data,
                data_id=i,
                category="performance_test",
                queue_name="batch_jobs"
            )
            jobs_batch.append(job)
    
    batch_time = time.time() - start_time
    
    # Show results
    improvement = ((individual_time - batch_time) / individual_time) * 100
    
    print(f"‚è±Ô∏è  Without SyncClient: {individual_time:.2f} seconds")
    print(f"‚ö° With SyncClient: {batch_time:.2f} seconds")
    print(f"üöÄ Improvement: {improvement:.0f}% faster!")
    
    return len(jobs_individual) + len(jobs_batch)


def batch_operations_demo():
    """
    Demonstrate various batch operations using SyncClient.
    """
    print("\nüì¶ Batch Operations Demo")
    print("-" * 30)
    
    with SyncClient() as client:
        # Batch 1: Data processing jobs
        print("üì§ Enqueueing data processing jobs...")
        data_jobs = []
        for i in range(5):
            job = client.enqueue(
                process_data,
                data_id=i + 1000,
                category="batch_demo",
                queue_name="batch_jobs"
            )
            data_jobs.append(job)
        
        print(f"‚úÖ Enqueued {len(data_jobs)} data processing jobs")
        
        # Batch 2: Notification jobs
        print("üì§ Enqueueing notification jobs...")
        notification_jobs = []
        users = ["alice", "bob", "charlie"]
        for user in users:
            job = client.enqueue(
                send_notification,
                user_id=user,
                message="Batch processing completed",
                queue_name="default"
            )
            notification_jobs.append(job)
        
        print(f"‚úÖ Enqueued {len(notification_jobs)} notification jobs")
        
        # Batch 3: Scheduled jobs
        print("üì§ Scheduling future report jobs...")
        scheduled_jobs = []
        
        # Schedule a job for 30 seconds from now
        future_time = datetime.now(timezone.utc) + timedelta(seconds=30)
        job1 = client.enqueue_at(
            future_time,
            generate_report,
            report_type="daily",
            date="2024-01-15",
            queue_name="default"
        )
        scheduled_jobs.append(job1)
        
        # Schedule a job for 1 minute from now
        job2 = client.enqueue_in(
            timedelta(minutes=1),
            generate_report,
            report_type="weekly",
            date="2024-01-15",
            queue_name="default"
        )
        scheduled_jobs.append(job2)
        
        print(f"‚úÖ Scheduled {len(scheduled_jobs)} future jobs")
        
        # Batch 4: Queue management
        print("üì§ Managing queues...")
        
        # Create some test jobs then purge them
        test_jobs = []
        for i in range(3):
            job = client.enqueue(
                process_data,
                data_id=i + 2000,
                category="test",
                queue_name="test_queue"
            )
            test_jobs.append(job)
        
        # Purge the test queue
        purged_count = client.purge_queue("test_queue")
        print(f"‚úÖ Purged {purged_count} jobs from test queue")
        
        total_jobs = len(data_jobs) + len(notification_jobs) + len(scheduled_jobs)
        print(f"\nüéØ Batch operations completed! Total jobs: {total_jobs}")
        
        return total_jobs


def main():
    """
    Main demonstration function.
    """
    print("üöÄ NAQ SyncClient Performance Demo")
    print("=" * 40)
    
    try:
        # Performance comparison
        perf_jobs = performance_test()
        
        # Batch operations demo
        batch_jobs = batch_operations_demo()
        
        total_jobs = perf_jobs + batch_jobs
        
        print(f"\nüéâ Demo completed successfully!")
        print(f"üìä Total jobs enqueued: {total_jobs}")
        print("\nüí° Key Benefits of SyncClient:")
        print("   - Connection reuse reduces overhead")
        print("   - Better performance for batch operations")
        print("   - Automatic resource cleanup")
        print("   - Simpler code with context managers")
        
        print("\nüìã Next steps:")
        print("   - Check your worker logs to see job processing")
        print("   - Try the worker management example")
        print("   - Explore advanced features like job dependencies")
        
    except Exception as e:
        print(f"‚ùå Error running demo: {e}")
        print("\nüîß Troubleshooting:")
        print("   - Is NATS running? (cd docker && docker-compose up -d)")
        print("   - Are workers running? (naq worker default batch_jobs)")
        print("   - Is NAQ_JOB_SERIALIZER=json set?")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())